{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3716096,"sourceType":"datasetVersion","datasetId":2222684}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.ensemble import RandomForestClassifier\nimport nltk\n\n\nnltk.download('stopwords')\ntrain = pd.read_csv(\"/kaggle/input/bagofwordsmeto/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n\nprint(\"训练数据形状:\", train.shape)\nprint(train.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T04:50:01.155696Z","iopub.execute_input":"2025-08-01T04:50:01.156114Z","iopub.status.idle":"2025-08-01T04:50:33.534670Z","shell.execute_reply.started":"2025-08-01T04:50:01.156089Z","shell.execute_reply":"2025-08-01T04:50:33.533593Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Error loading stopwords: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\n","output_type":"stream"},{"name":"stdout","text":"训练数据形状: (25000, 3)\n         id  sentiment                                             review\n0  \"5814_8\"          1  \"With all this stuff going down at the moment ...\n1  \"2381_9\"          1  \"\\\"The Classic War of the Worlds\\\" by Timothy ...\n2  \"7759_3\"          0  \"The film starts with a manager (Nicholas Bell...\n3  \"3630_4\"          0  \"It must be assumed that those who praised thi...\n4  \"9495_8\"          1  \"Superbly trashy and wondrously unpretentious ...\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"def review_to_words(raw_review):\n \n    #去除HTML标签\n    review_text = BeautifulSoup(raw_review, \"html.parser\").get_text()\n    \n    #保留字母字符\n    letters_only = re.sub(\"[^a-zA-Z]\", \" \", review_text)\n    \n    #转换为小写并分割成单词\n    words = letters_only.lower().split()\n    \n    #将停用词转换为集合(提高查找速度)\n    stops = set(stopwords.words(\"english\"))\n    \n    #去除停用词\n    meaningful_words = [w for w in words if w not in stops]\n    \n    #将单词列表合并为一个字符串返回\n    return \" \".join(meaningful_words)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T04:51:44.570983Z","iopub.execute_input":"2025-08-01T04:51:44.571427Z","iopub.status.idle":"2025-08-01T04:51:44.577829Z","shell.execute_reply.started":"2025-08-01T04:51:44.571326Z","shell.execute_reply":"2025-08-01T04:51:44.576210Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"#影评数量\nnum_reviews = train[\"review\"].size\n\n#初始化一个空列表来存储清洗后的影评\nclean_train_reviews = []\n\nprint(\"开始清洗和解析训练集中的影评...\")\n\n#处理每条影评\nfor i in range(num_reviews):\n    if (i+1) % 1000 == 0:\n        print(f\"已处理 {i+1} 条影评，共 {num_reviews} 条\")\n    #清洗函数\n    clean_train_reviews.append(review_to_words(train[\"review\"][i]))\n\nprint(\"\\n清洗完成!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T04:50:33.543997Z","iopub.execute_input":"2025-08-01T04:50:33.544376Z","iopub.status.idle":"2025-08-01T04:50:43.102934Z","shell.execute_reply.started":"2025-08-01T04:50:33.544357Z","shell.execute_reply":"2025-08-01T04:50:43.102217Z"}},"outputs":[{"name":"stdout","text":"开始清洗和解析训练集中的影评...\n已处理 1000 条影评，共 25000 条\n已处理 2000 条影评，共 25000 条\n已处理 3000 条影评，共 25000 条\n已处理 4000 条影评，共 25000 条\n已处理 5000 条影评，共 25000 条\n已处理 6000 条影评，共 25000 条\n已处理 7000 条影评，共 25000 条\n已处理 8000 条影评，共 25000 条\n已处理 9000 条影评，共 25000 条\n已处理 10000 条影评，共 25000 条\n已处理 11000 条影评，共 25000 条\n已处理 12000 条影评，共 25000 条\n已处理 13000 条影评，共 25000 条\n已处理 14000 条影评，共 25000 条\n已处理 15000 条影评，共 25000 条\n已处理 16000 条影评，共 25000 条\n已处理 17000 条影评，共 25000 条\n已处理 18000 条影评，共 25000 条\n已处理 19000 条影评，共 25000 条\n已处理 20000 条影评，共 25000 条\n已处理 21000 条影评，共 25000 条\n已处理 22000 条影评，共 25000 条\n已处理 23000 条影评，共 25000 条\n已处理 24000 条影评，共 25000 条\n已处理 25000 条影评，共 25000 条\n\n清洗完成!\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"print(\"创建词袋特征...\")\n\nvectorizer = CountVectorizer(\n    analyzer=\"word\",\n    tokenizer=None,\n    preprocessor=None,\n    stop_words=None,\n    max_features=5000 \n)\n\n#拟合模型并转换训练数据\ntrain_data_features = vectorizer.fit_transform(clean_train_reviews)\ntrain_data_features = train_data_features.toarray()\nprint(\"特征矩阵形状:\", train_data_features.shape)\nvocab = vectorizer.get_feature_names_out()\nprint(\"词汇表前10个词:\", vocab[:10])\n\n#统计每个词出现次数\ndist = np.sum(train_data_features, axis=0)\nfor tag, count in zip(vocab[:10], dist[:10]):\n    print(count, tag)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T04:50:43.104760Z","iopub.execute_input":"2025-08-01T04:50:43.105112Z","iopub.status.idle":"2025-08-01T04:50:46.104150Z","shell.execute_reply.started":"2025-08-01T04:50:43.105094Z","shell.execute_reply":"2025-08-01T04:50:46.103255Z"}},"outputs":[{"name":"stdout","text":"创建词袋特征...\n特征矩阵形状: (25000, 5000)\n词汇表前10个词: ['abandoned' 'abc' 'abilities' 'ability' 'able' 'abraham' 'absence'\n 'absent' 'absolute' 'absolutely']\n187 abandoned\n125 abc\n108 abilities\n454 ability\n1259 able\n85 abraham\n116 absence\n83 absent\n352 absolute\n1485 absolutely\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"print(\"训练随机森林模型...\")\n\n#初始化\nforest = RandomForestClassifier(n_estimators=100)\n\n#拟合模型\nforest = forest.fit(train_data_features, train[\"sentiment\"])\n\nprint(\"模型训练完成!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T04:50:46.104984Z","iopub.execute_input":"2025-08-01T04:50:46.105224Z","iopub.status.idle":"2025-08-01T04:51:29.991904Z","shell.execute_reply.started":"2025-08-01T04:50:46.105206Z","shell.execute_reply":"2025-08-01T04:51:29.991018Z"}},"outputs":[{"name":"stdout","text":"训练随机森林模型...\n模型训练完成!\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/bagofwordsmeto/labeledTrainData.tsv\", header=0, delimiter=\"\\t\", quoting=3)\n\n#清洗\nprint(\"清洗和解析测试集影评...\")\nnum_reviews = len(test[\"review\"])\nclean_test_reviews = []\n\nfor i in range(num_reviews):\n    if (i+1) % 1000 == 0:\n        print(f\"已处理 {i+1} 条影评，共 {num_reviews} 条\")\n    clean_review = review_to_words(test[\"review\"][i])\n    clean_test_reviews.append(clean_review)\n\n# 将测试数据转换为词袋特征\ntest_data_features = vectorizer.transform(clean_test_reviews)\ntest_data_features = test_data_features.toarray()\n\n#预测\nresult = forest.predict(test_data_features)\n\n#提交文件\noutput = pd.DataFrame(data={\"id\": test[\"id\"], \"sentiment\": result})\noutput.to_csv(\"Bag_of_Words_model.csv\", index=False, quoting=3)\n\nprint(\"预测结果已保存到Bag_of_Words_model.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-08-01T04:51:29.993658Z","iopub.execute_input":"2025-08-01T04:51:29.994556Z","iopub.status.idle":"2025-08-01T04:51:44.569915Z","shell.execute_reply.started":"2025-08-01T04:51:29.994525Z","shell.execute_reply":"2025-08-01T04:51:44.568861Z"}},"outputs":[{"name":"stdout","text":"清洗和解析测试集影评...\n已处理 1000 条影评，共 25000 条\n已处理 2000 条影评，共 25000 条\n已处理 3000 条影评，共 25000 条\n已处理 4000 条影评，共 25000 条\n已处理 5000 条影评，共 25000 条\n已处理 6000 条影评，共 25000 条\n已处理 7000 条影评，共 25000 条\n已处理 8000 条影评，共 25000 条\n已处理 9000 条影评，共 25000 条\n已处理 10000 条影评，共 25000 条\n已处理 11000 条影评，共 25000 条\n已处理 12000 条影评，共 25000 条\n已处理 13000 条影评，共 25000 条\n已处理 14000 条影评，共 25000 条\n已处理 15000 条影评，共 25000 条\n已处理 16000 条影评，共 25000 条\n已处理 17000 条影评，共 25000 条\n已处理 18000 条影评，共 25000 条\n已处理 19000 条影评，共 25000 条\n已处理 20000 条影评，共 25000 条\n已处理 21000 条影评，共 25000 条\n已处理 22000 条影评，共 25000 条\n已处理 23000 条影评，共 25000 条\n已处理 24000 条影评，共 25000 条\n已处理 25000 条影评，共 25000 条\n预测结果已保存到Bag_of_Words_model.csv\n","output_type":"stream"}],"execution_count":17}]}